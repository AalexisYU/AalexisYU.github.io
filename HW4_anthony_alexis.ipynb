{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AalexisYU/AalexisYU.github.io/blob/master/HW4_anthony_alexis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA6EbkfCbYpP"
      },
      "source": [
        "# Phys 3130\n",
        "\n",
        "#HW4: Train-test Split and Cross-Validation Lab\n",
        "\n",
        "Author: Dr. Elaina A. Hyde\n",
        "\n",
        "Due Date: April 02, 2025 10pm\n",
        "\n",
        "-----\n",
        "\n",
        "This notebook is a guided code including all questions for HW4. Students should make a copy and enter their solutions, avoiding copy-paste from online or Gemini. Please note, this is partial 'AI autocomplete' assignment, you are free to use any (cited) web references. If you have AI generated code, make SURE that you have explained and cited it, and leave in your prompt as well as your original contribution (use the hashtag to include comments in your code).\n",
        "\n",
        "### How to turn in this homework:\n",
        "* **Step 1:** make a copy in your local google drive of this notebook and rename it to HW4_firstname_lastname.ipynb\n",
        "\n",
        "* **Step 2:** go to your GitHub account and select the private class repo you created.\n",
        "\n",
        "* **Step 3:** Load your .ipynb file into your private github\n",
        "\n",
        "* **Step 4:** your upload date timestamp is your due date check, do not upload past the deadline or you will lose marks of 10% for every hour late.\n",
        "---\n",
        "Student name: [Anthony Alexis]\n",
        "\n",
        "---\n",
        "## Review of train/test validation methods\n",
        "\n",
        "We've discussed basic models.\n",
        "\n",
        "Make sure to review overfitting, underfitting, and how to validate the \"generalizeability\" of your models by testing them on unseen data.\n",
        "\n",
        "In this homework you'll practice two related validation methods:\n",
        "1. **train/test split**\n",
        "2. **k-fold cross-validation**\n",
        "\n",
        "Train/test split and k-fold cross-validation both serve two useful purposes:\n",
        "- We prevent overfitting by not using all the data, and\n",
        "- We retain some remaining data to evaluate our model.\n",
        "\n",
        "In the case of cross-validation, the model fitting and evaluation is performed multiple times on different train/test splits of the data.\n",
        "\n",
        "Ultimately we can the training and testing validation framework to compare multiple models on the same dataset. This could be comparisons of two linear models, or of completely different models on the same data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxTdMEc6bYpR"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "For your independent practice, fit **three different models** on the Boston housing data. For example, you could pick three different subsets of variables, one or more polynomial models, or any other model that you like.\n",
        "\n",
        "**Start with train/test split validation:**\n",
        "* Fix a testing/training split of the data\n",
        "* Train each of your models on the training data\n",
        "* Evaluate each of the models on the test data\n",
        "* Rank the models by how well they score on the testing data set.\n",
        "\n",
        "**Then try K-Fold cross-validation:**\n",
        "* Perform a k-fold cross validation and use the cross-validation scores to compare your models. Did this change your rankings?\n",
        "* Try a few different K-splits of the data for the same models.\n",
        "\n",
        "If you're interested, try a variety of response variables.  We start with **MEDV** (the `.target` attribute from the dataset load method)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zh2_hmuabYpR"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib inline\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j1CKD0jybYpS"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "#this loads the free california housing data\n",
        "#remember, why do we NOT want to use the boston set?\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html\n",
        "california = fetch_california_housing()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame for easy manipulation\n",
        "columns = california.feature_names\n",
        "\n",
        "#model features and target\n",
        "X = pd.DataFrame(california.data, columns=california.feature_names)\n",
        "y = california.target\n",
        "\n",
        "# Show first few rows of the dataframe\n",
        "print(X.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgS96Foug9Zt",
        "outputId": "b5f86f84-517f-4891-86f1-ff5163326ab3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
            "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
            "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
            "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
            "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
            "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
            "\n",
            "   Longitude  \n",
            "0    -122.23  \n",
            "1    -122.22  \n",
            "2    -122.24  \n",
            "3    -122.25  \n",
            "4    -122.25  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs0-4gsXbYpS"
      },
      "source": [
        "### Q1. Clean up any data problems\n",
        "\n",
        "Load the data.  Fix any problems, if applicable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZU9jgEubYpS",
        "outputId": "806bfb7a-46d5-4a6d-9aa0-ce18b88f07c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are no blank rows in this data.\n",
            "There are no duplicate rows in this data.\n",
            "No data cleaning was necessary.\n"
          ]
        }
      ],
      "source": [
        "# California data is from SKlearn so it is reasonably clean\n",
        "#read up on the columns in SKlearn documentation and enter your solution\n",
        "#using code and text\n",
        "\n",
        "# Check for blank values or duplicate rows\n",
        "blank = 0\n",
        "duplicates = 0\n",
        "if X.isnull().values.any():\n",
        "    print(X.isnull().sum())\n",
        "    blank = 1\n",
        "\n",
        "if X.duplicated().any():\n",
        "    print(X.duplicated().sum())\n",
        "    duplicates = 1\n",
        "\n",
        "\n",
        "# Apply changes, if necessary.\n",
        "if blank == 1:\n",
        "    X_clean = X.dropna()\n",
        "    Y_clean = y[X_clean.index] #ai autocomplete used after I put in my if statement. There was no prompt, I pressed tab because I liked what it suggested; it looked correct\n",
        "    print(f\"There were blank rows present in this data. They have now been removed.\")\n",
        "else:\n",
        "    print(\"There are no blank rows in this data.\")\n",
        "\n",
        "if duplicates == 1:\n",
        "    X_clean = X.drop_duplicates()\n",
        "    Y_clean = y[X_clean.index] #ai autocomplete used above, I just re-applied the same code for duplicate rows.\n",
        "    print(f\"There were duplicate rows present in this data. They have now been removed.\")\n",
        "else:\n",
        "    print(f\"There are no duplicate rows in this data.\")\n",
        "\n",
        "\n",
        "\n",
        "# Print a final message if there was no cleaning done.\n",
        "if blank == 0 and duplicates == 0:\n",
        "    print(f\"No data cleaning was necessary.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6a6_XtYbYpT"
      },
      "source": [
        "### Q2. Select 3-4 variables with your dataset to perform a 50/50 test train split on\n",
        "\n",
        "- Use sklearn.\n",
        "- Score and plot your predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPRArhkJbYpT"
      },
      "outputs": [],
      "source": [
        "#X.columns will print your column names, as long as you have saved X correctly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#what does a 50/50 split look like, how about a 80/20 split?\n",
        "# Hint: Split dataset into training and test sets\n",
        "#X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=??, random_state=42)"
      ],
      "metadata": {
        "id": "SGzVwoAoh6GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYTfhaJ4bYpT"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "predictors = ['MedInc','HouseAge', u'AveRooms', 'Population']\n",
        "\n",
        "#Regression models are ideal for our task, as weâ€™re trying to predict continuous values\n",
        "#(in this case, house prices). Let's use a simple Linear Regression model to start:\n",
        "\n",
        "# Instantiate the model\n",
        "\n",
        "# Fit the model on training data\n",
        "\n",
        "# Predict values using the test set\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "#Return the coefficient of determination of the prediction R2\n",
        "#this can be done 2 ways (probably more)\n",
        "\n",
        "#print(\"Mean Squared Error: \", mse)\n",
        "#print(\"R2 Score: \", r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm91VMeLbYpV"
      },
      "outputs": [],
      "source": [
        "#compare predicted results to test results\n",
        "#hint: use jointplot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iSx4AwfbYpV"
      },
      "source": [
        "### Q3. Try 70/30 and 90/10 split\n",
        "- Score and plot.  \n",
        "- How do your metrics change?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9sLoWb7lM_9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGpxZCg_bYpW"
      },
      "source": [
        "### Q4. Try K-Folds cross-validation with K between 5-10 for your regression.\n",
        "\n",
        "- What seems optimal?\n",
        "- How do your scores change?  \n",
        "- What the variance of scores like?\n",
        "- Try different folds to get a sense of how this impacts your score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UVU_fmYbYpX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "from sklearn import metrics\n",
        "\n",
        "# iterate through folds 5-10\n",
        "\n",
        "# Perform cross-validation\n",
        "\n",
        "# Make cross-validated predictions\n",
        "#print(\"Cross-Predicted R2:\", r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFik9BgAbYpX"
      },
      "source": [
        "### Q5. Optimize the $R^2$ score\n",
        "\n",
        "Can you optimize your R^2 by selecting the best features and validating the model using either train/test split or K-Folds?\n",
        "\n",
        "Your code will need to iterate through the different combinations of predictors, cross-validate the current model parameterization, and determine which set of features performed best.\n",
        "\n",
        "The number of K-folds is up to you.\n",
        "\n",
        "> *Hint:* the `itertools` package is useful for combinations and permutations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEraOHMRbYpX"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekyZAfNZbYpX"
      },
      "source": [
        "### Q6 Can you explain what could be wrong with the approach in Question 5?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1-VJy-8yOrgw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIL3_kwcbYpY"
      },
      "source": [
        "### Q7. Explore another target variable and practice `patsy` formulas\n",
        "\n",
        "Can you find another response variable, given a combination of predictors, that can be predicted accurately through the exploration of different predictors in this dataset?\n",
        "\n",
        "**Try out using patsy to construct your target and predictor matrices from formula strings.**\n",
        "\n",
        "*Tip: Check out pairplots, coefficients, and pearson scores.*\n",
        "\n",
        "*Tip: For more on patsy models see: https://witve.com/codes/comprehensive-guide-to-patsy-for-building-statistical-models-in-python/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afuSi2yybYpY"
      },
      "outputs": [],
      "source": [
        "# Check out variable relations\n",
        "import seaborn as sns\n",
        "#sns.pairplot(X) as long as X is defined correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQmtnZMEbYpY"
      },
      "outputs": [],
      "source": [
        "import patsy\n",
        "#df = X.copy()\n",
        "\n",
        "# Add response to core DataFrame\n",
        "#df['MedInc'] = y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uhKf5j4bYpY"
      },
      "outputs": [],
      "source": [
        "# Easily change your variable predictors without reslicing your DataFrame\n",
        "#AveBedrooms and AveRooms correlate\n",
        "#new target variable median income MedInc\n",
        "#yp, Xp = patsy.dmatrices(\" MedInc ~ Population + AveRooms\", data=df, return_type=\"dataframe\")\n",
        "\n",
        "# \"unravel\" y\n",
        "\n",
        "#make your train test split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqKLO9tRbYpY"
      },
      "outputs": [],
      "source": [
        "# Build a new model and calculate the score:\n",
        "#lm = LinearRegression()\n",
        "\n",
        "#print(\"R^2 Score: \", metrics.r2_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZfdECkMbYpY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}